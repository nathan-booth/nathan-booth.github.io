---
layout: post
title: Facebook and Value
---

Facebook asked me a survey question today that I found interesting enough to answer. 

Is Facebook good for the world?

Below is my submitted response.

> Facebook seems to be good for loosely connecting people into loose tribes. It optimizes for engagement - and I assume other factors invisible to me - but it does not seem good at optimizing for indicators of happiness (like purpose, personal growth, overcoming challenges) or prosocial behavior, especially when those things are in tension with engagement. If Facebook weighted measurements that improve people rather than people's instinctive and sometimes negatively tribal behaviors, it would be better for the world.

I wanted to expand a bit more though, so here is a longer meditation on the question.

Caveats

I do not know the internal workings of Facebook. I read articles about it from time to time if it seems interesting and appears in my RSS feed or Pocket newsletter. There is a bias based on those filters. I am not immune to availability bias, so I may be overweighting the bad and finding it difficult to recall the good.

The Good

Facebook connects people in loose networks. It can help maintain close connections, like friends who live in different cities. It can expand one's network of acquaintances, leading to an expanded worldview or support network. A loose network can lead to unexpected emotional connections or help finding work.

I use Facebook to contact distant friends, organize ultimate, joke, and humblebrag.

Could Go Either Way

Facebook gets people to use Facebook. My judgment depends on the opportunity cost. If I'm on Facebook instead of attending to my friend at dinner, then the opportunity cost is high. If I check Facebook more than once a day without communicating with someone in a constructive way, then what is the value? Outrage and mindless activity are rarely valuable.

Facebook connects people to information. When it's confirming information, either neutral or bad. I do not need more evidence or social proof that I disagree with many of Donald Trump's actions and policies. That's already my default belief.When the information is disconfirming beliefs, value depends on the information's veracity. We do not need more hatred or conspiracy theories.  I get value from Facebook suggesting an article that challenges my thinking with strong arguments and evidence. Content for the sake of content and shares for the sake of shares lack value.

The Bad

Facebook does not curb our negative tribal impulses, nor our faulty or lazy thinking. Instead it encourages these negative outcomes in a feedback loop. 

My liberal friend Susan sees some abhorrent news story about a conservative.

She feels righteous outrage so she shares it with Amin.

Amin feel righteous outrage so Amin shares it again and confirms the beliefs of the other liberals in our Facebook network.

Outrage grows. The sense of broader community with conservatives weakens. We claim and agree that conservatives are racist, don't care for poor or black people, are moral hypocrites, will cut off their nose to spite their face, can't really believe the stuff they say, etc.

Repeat.

(You can exchange liberal beliefs about conservatives with conservative beliefs about liberals. Liberals hate rich people, hate religion, are amoral, hate capitalism, seek a communist authoritarian state, are hypocrites, can't really believe the stuff they say, etc.)

Facebook does not attempt to improve our behavior because it optimizes engagement. It optimizes for addictiveness, not social health.

Facebook could be good for the world if it optimized for metrics that improve people's relations, behavior, or thinking. The problem is that optimizing multiple metrics causes tension. The tension between moral values and profit growth will make improvement difficult. 

Facebook is in a trap. It optimizes for profit. Profit generation is amoral. There comes a choice with a trade off between profit-growing and adhering to a moral value. The profit-growing choice wins as long as abandoning the value lacks profit-eating costs. Repeat until profit is fully optimized and you have a system in which everyone hates the system but are incentivized to maintain it. For similar traps see: electronic healthcare records, Congressional approval, corporate welfare, corporate patronage (e.g., Amazon's second headquarters or sports stadiums), replication and publication bias in science, etc.

Context Matters

When Facebook asks this question matters. In 2006 or whenever it was I first logged on, I loved it. I kept in contact with my high school friends who attended different colleges or moved away. I maintained valuable relationships. But in 2016, I'd say Facebook did more harm than good. People built their own bubbles with Facebook's encouragement, then forgot they were living in a bubble. And Facebook claimed their technology is neutral while its users became increasingly extreme.

TL;DR

Current answer, subject to update: Facebook is not good for the world.
